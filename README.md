# Caching em Redes com Perdas e Atrasos

![GitHub repo size](https://img.shields.io/github/repo-size/siliconemonster/AD-TrabalhoFinal?color=a21360&style=for-the-badge)
![GitHub language count](https://img.shields.io/github/languages/count/siliconemonster/AD-TrabalhoFinal?color=a21360&style=for-the-badge)
![Made With](https://img.shields.io/badge/Made%20With-Python-lightgrey?color=a21360&style=for-the-badge)
![GitHub repo file count](https://img.shields.io/github/directory-file-count/siliconemonster/AD-TrabalhoFinal?color=a21360&style=for-the-badge)
![GitHub last commit](https://img.shields.io/github/last-commit/siliconemonster/AD-TrabalhoFinal?color=a21360&style=for-the-badge)

# Ãndice

- [IntroduÃ§Ã£o](#introduÃ§Ã£o)
- [CenÃ¡rio I - Sem perdas e sem atrasos](#cenÃ¡rio-i)
  - [Simulador CenÃ¡rio I](#simulador-cenÃ¡rio-i)
- [CenÃ¡rio II â€“ Com perdas e sem atrasos](#cenÃ¡rio-ii)
  - [Simulador CenÃ¡rio II](#simulador-cenÃ¡rio-ii)
- [CenÃ¡rio III â€“ Com perdas e com atrasos](#cenÃ¡rio-iii)
  - [Simulador CenÃ¡rio III](#simulador-cenÃ¡rio-iii)
- AplicaÃ§Ã£o dos Simuladores e ConclusÃ£o(#aplicaÃ§Ã£o-dos-simuladores-e-conclusÃ£o)
- [Colaboradores](#colaboradores)
- [LicenÃ§a](#licenÃ§a)

# IntroduÃ§Ã£o

O objetivo deste projeto Ã© construir um simulador de um sistema de 2 caches em redes (FIFO, LRU, Random e EstÃ¡ticas) com perdas e atrasos, de acordo com 4 cenÃ¡rios possÃ­veis. SÃ£o eles: canais sem perdas e sem atrasos, canais com perdas e sem atrasos, e dois canais com perdas e com atrasos.
TambÃ©m devemos efetuar os cÃ¡lculos utilizando nossos conhecimentos sobre cadeias de Markov, e compararmos com o intervalo de confianÃ§a obtido em cada simulaÃ§Ã£o quando possÃ­vel. Calcularemos as probabilidades de sucesso, user miss, tempo mÃ©dio de serviÃ§o de requisiÃ§Ãµes, conforme o que for solicitado em cada cenÃ¡rio. 

Optamos pela linguagem Python, pois fornece uma gama de funÃ§Ãµes prÃ©-existentes para o nosso auxÃ­lio, entre elas funÃ§Ãµes para plotagem de grÃ¡ficos.

# CenÃ¡rio I

O cenÃ¡rio I (sem perdas e sem atrasos) Ã© composto por duas caches, cada uma com tamanho igual Ã  dois, nÃ£o hÃ¡ atrasos
nos canais de comunicaÃ§Ã£o e Ã© considerado o caso especial onde nÃ£o hÃ¡ chances de um canal falhar.
Dessa forma, a cada requisiÃ§Ã£o feita pelo cliente, apenas Ã© avaliado se as caches possuem ou nÃ£o o
conteÃºdo requisitado e uma mudanÃ§a Ã© realizada nos conteÃºdos da cache de acordo com seu modelo.
Nosso propÃ³sito nesse cenÃ¡rio Ã© identificar qual a probabilidade de uma requisiÃ§Ã£o ser atendida com
sucesso, ou seja, pelo menos uma das duas caches possuir o conteÃºdo requisitados para cada uma das
seguintes composiÃ§Ãµes:

- 2 caches FIFO; 
- 2 caches LRU; 
- 2 caches Random; 
- 2 caches EstÃ¡ticas

## Simulador CenÃ¡rio I

Para simularmos o cenÃ¡rio I, criamos um simulador de eventos de tempo contÃ­nuo onde
requisiÃ§Ãµes de cada conteÃºdo chegam numa taxa igual a probabilidade do conteÃºdo ser requisitado dada
e verificamos quantas delas foram atendidas por pelo menos uma das duas caches. Abaixo, temos uma
melhor descriÃ§Ã£o do funcionamento do simulador e da funÃ§Ã£o que o implementa.
O simulador possui um sistema com duas caches onde podemos definir o tamanho delas, o
nÃºmero de conteÃºdos possÃ­veis de serem requisitados em cada experimento, a probabilidade de
requisiÃ§Ã£o de cada conteÃºdo e os estados iniciais das caches. Inicialmente, as caches sÃ£o inicializadas
com os estados passados, caso nÃ£o sejam passados, elas sÃ£o inicializadas de forma aleatÃ³ria com os
conteÃºdos possÃ­veis, que nesse caso serÃ£o representados por nÃºmeros inteiros de 1 ao â€œnumConteudosâ€
dado.

ApÃ³s isso, agenda-se um evento de uma requisiÃ§Ã£o para cada conteÃºdo na lista de eventos, esse
evento indica qual o tempo em que a requisiÃ§Ã£o irÃ¡ acontecer e qual conteÃºdo estarÃ¡ sendo requisitado.
O tempo do agendamento Ã© gerado de forma aleatÃ³ria seguindo a distribuiÃ§Ã£o exponencial tendo como
parÃ¢metro a taxa de chegada do conteÃºdo, que aqui adotamos como 1 * probabilidade do conteÃºdo ser
requisitado. A cada vez que um evento Ã© adicionado, a lista Ã© ordenada em funÃ§Ã£o dos tempos
apresentados em cada evento.

Com as caches inicializadas e uma requisiÃ§Ã£o agendada para cada conteÃºdo, comeÃ§a-se a
realizaÃ§Ã£o dos eventos, ou seja, as requisiÃ§Ãµes agendadas comeÃ§am a ser a realizadas. Em termos de
cÃ³digo, inicia-se um loop em cima da lista de eventos, onde em cada iteraÃ§Ã£o, a requisiÃ§Ã£o com menor
tempo presente na lista Ã© encaminhada paras as duas caches e para cada cache Ã© realizado o seguinte
processo: analisa-se se a cache possui o conteÃºdo requisitado e assim marca-se se a requisiÃ§Ã£o foi
atendida ou nÃ£o, em ambos os casos a cache muda de estado seguindo o padrÃ£o do tipo de cache
especificado. ApÃ³s ser encaminhada para as duas caches, verifica-se a requisiÃ§Ã£o foi atendida por pelo
menos uma das caches, se sim, Ã© marcado como sucesso. ApÃ³s uma requisiÃ§Ã£o ser feita, Ã© agendada
uma nova requisiÃ§Ã£o para o mesmo conteÃºdo onde o tempo do agendamento Ã© gerado de forma aleatÃ³ria
seguindo a distribuiÃ§Ã£o exponencial com parÃ¢metro igual a probabilidade do conteÃºdo, dessa forma
garantimos que cada conteÃºdo seja requisitado seguindo sua taxa de chegada.

ApÃ³s o nÃºmero de requisiÃ§Ãµes pedidas serem feitas, verifica-se o nÃºmero de sucessos e
finalmente calcula-se a probabilidade de sucesso fazendo o seguinte cÃ¡lculo:
ğ‘›Ãºğ‘šğ‘’ğ‘Ÿğ‘œ ğ‘‘ğ‘’ ğ‘ ğ‘¢ğ‘ğ‘’ğ‘ ğ‘ ğ‘œğ‘ /ğ‘›Ãºğ‘šğ‘’ğ‘Ÿğ‘œ ğ‘‘ğ‘’ ğ‘Ÿğ‘’ğ‘ğ‘¢ğ‘–ğ‘ ğ‘–Ã§Ãµğ‘’ğ‘  ğ‘Ÿğ‘’ğ‘ğ‘™ğ‘–ğ‘§ğ‘ğ‘‘ğ‘ğ‘ 

O simulador do cenÃ¡rio I Ã© dado pela funÃ§Ã£o â€œsimulacaoCenario1()â€ que tem os seguintes
parÃ¢metros de entrada:
* numRequisicoes - NÃºmero de requisiÃ§Ãµes que serÃ£o realizadas no experimento. Deve ser um
nÃºmero inteiro maior que 0;
* caso - qual Ã© o caso/tipo das caches. Os possÃ­veis valores de entrada sÃ£o: "FIFO", "LRU",
"Random" ou "Estatica";
* numConteudos - nÃºmero de conteÃºdos que podem ser requisitados. Deve ser um nÃºmero
inteiro maior que 0;
* tamCache - tamanho das caches. Deve ser um nÃºmero inteiro maior que 0;
* probabilidades - probabilidade de cada conteÃºdo ser requisitado. Deve ser passado uma lista
de tamanho igual ao nÃºmero de conteÃºdos. Por exemplo, se sÃ£o trÃªs conteÃºdos e possuem probabilidade
de requisiÃ§Ã£o uniforme, a lista passada deverÃ¡ ser [1/3,1/3,1/3];
* depurar - Booleano para indicar se deseja imprimir a depuraÃ§Ã£o do cÃ³digo ou nÃ£o. O default
Ã© o valor "False", onde nÃ£o se depura;
* cache1_inicial - Estado inicial de uma cache. Se nada for passado, ela irÃ¡ ser inicializada
aleatoriamente;
* cache2_inicial - Estado inicial da outra cache. Se nada for passado, ela irÃ¡ ser inicializada
aleatoriamente.
* cachesDiferentes - Booleano para indicar se deseja que as caches comecem em estados
diferentes ou iguais. O default Ã© o valor "True", onde comeÃ§am com em estados diferentes.


[â¬† Voltar ao topo](#caching-em-redes-com-perdas-e-atrasos)

# CenÃ¡rio II

O cenÃ¡rio II (com perdas e sem atrasos) tambÃ©m Ã© composto por duas caches, cada uma com tamanho igual Ã  dois, nÃ£o hÃ¡
atrasos nos canais de comunicaÃ§Ã£o, contudo hÃ¡ a probabilidade de um canal falhar. Dessa forma, a cada
requisiÃ§Ã£o feita pelo cliente, primeiramente Ã© avaliado se o canal funcionou e sÃ³ assim Ã© avaliado se a
cache possui ou nÃ£o o conteÃºdo requisitado. Nosso propÃ³sito nesse cenÃ¡rio Ã© identificar qual a
probabilidade de ocorrer um user miss que em outras palavras Ã© a probabilidade de uma requisiÃ§Ã£o nÃ£o
ser atendida, para cada uma das seguintes composiÃ§Ãµes:
- 2 caches FIFO; 
- 2 caches LRU; 
- 2 caches Random; 
- 2 caches EstÃ¡ticas

## Simulador CenÃ¡rio II

Para simularmos o cenÃ¡rio II, criamos um simulador de eventos de tempo contÃ­nuo muito
semelhante ou simulador do cenÃ¡rio I onde requisiÃ§Ãµes de cada conteÃºdo chegam a uma taxa igual a
probabilidade do conteÃºdo ser requisitado dada e verificamos quantas delas foram atendidas por pelo
menos uma das duas caches. A Ãºnica diferenÃ§a nesse caso Ã© que calcula-se se o canal falhou ou nÃ£o,
com probabilidade igual a p = 0.9 de funcionar, antes encaminhar para a cache, Abaixo, temos uma
melhor descriÃ§Ã£o do funcionamento do simulador e da funÃ§Ã£o que o implementa.

Como o cenÃ¡rio II se assemelha muito ao cenÃ¡rio I, a descriÃ§Ã£o do simulador Ã© bastante
semelhante. Temos entÃ£o que inicialmente, as caches sÃ£o inicializadas com os estados passados, caso
nÃ£o sejam passados, elas sÃ£o inicializadas de forma aleatÃ³ria com os conteÃºdos possÃ­veis, que nesse
caso serÃ£o representados por nÃºmeros inteiros de 1 ao numConteudos dado.

ApÃ³s isso, agenda-se um evento de uma requisiÃ§Ã£o para cada conteÃºdo na lista de eventos, esse
evento indica qual o tempo em que a requisiÃ§Ã£o irÃ¡ acontecer e qual conteÃºdo estarÃ¡ sendo requisitado.
O tempo do agendamento Ã© gerado de forma aleatÃ³ria seguindo a distribuiÃ§Ã£o exponencial tendo como
parÃ¢metro a taxa do conteÃºdo e a cada vez que um evento Ã© adicionado, a lista Ã© ordenada em funÃ§Ã£o
dos tempos apresentados em cada evento.

Com as caches inicializadas e uma requisiÃ§Ã£o agendada para cada conteÃºdo, comeÃ§a-se a
realizaÃ§Ã£o dos eventos, ou seja, as requisiÃ§Ãµes agendadas comeÃ§am a ser realizadas. Em termos de
cÃ³digo, inicia-se um loop em cima da lista de eventos, onde em cada iteraÃ§Ã£o, a requisiÃ§Ã£o com menor
tempo presente na lista Ã© encaminhada para as duas caches. Neste ponto que o cenÃ¡rio II se diferencia
do cenÃ¡rio I, neste caso hÃ¡ a probabilidade do canal que leva a requisiÃ§Ã£o atÃ© a cache falhar, e com isso
nÃ£o tem a possibilidade da requisiÃ§Ã£o ser atendida pela cache que por conta disso nÃ£o mudarÃ¡ de estado.

EntÃ£o para cada cache Ã© realizado o seguinte processo: tenta-se encaminhar a requisiÃ§Ã£o para
cache, para isso gera-se um nÃºmero entre 0 e 1, se o nÃºmero for menor ou igual ao parÃ¢metro $p$ (que
por default Ã© $0.9$, o que implica que o canal tem 90% de chance de funcionar), o canal funciona e a
requisiÃ§Ã£o alcanÃ§a a cache e assim analisa-se se a cache possui o conteÃºdo requisitado e marca-se se a
requisiÃ§Ã£o foi atendida ou nÃ£o, em ambos os casos em que o canal funciona, a cache muda de estado
seguindo o padrÃ£o do tipo de cache especificado. ApÃ³s a tentativa de se encaminhar a requisiÃ§Ã£o para
as duas caches, verifica-se se a requisiÃ§Ã£o foi atendida por pelo menos uma das caches, se sim, Ã© marcado
como sucesso. ApÃ³s uma requisiÃ§Ã£o ser feita, Ã© agendada uma nova requisiÃ§Ã£o para o mesmo conteÃºdo
onde o tempo do agendamento Ã© gerado de forma aleatÃ³ria seguindo a distribuiÃ§Ã£o exponencial com
parÃ¢metro igual a probabilidade do conteÃºdo, dessa forma garantimos que cada conteÃºdo seja
requisitado seguindo sua taxa de chegada.

ApÃ³s o nÃºmero de requisiÃ§Ãµes pedidas serem feitas, verifica-se o nÃºmero de casos em que nÃ£o
ocorreu user miss, ou seja, os eventos onde a requisiÃ§Ã£o foi atendida e finalmente calcula-se a
probabilidade de user miss fazendo o seguinte cÃ¡lculo: 

(ğ‘›Ãºğ‘šğ‘’ğ‘Ÿğ‘œ ğ‘‘ğ‘’ ğ‘Ÿğ‘’ğ‘ğ‘¢ğ‘–ğ‘ ğ‘–Ã§Ãµğ‘’ğ‘  ğ‘Ÿğ‘’ğ‘ğ‘™ğ‘–ğ‘§ğ‘ğ‘‘ğ‘ğ‘  âˆ’ ğ‘›Ãºğ‘šğ‘’ğ‘Ÿğ‘œ ğ‘‘ğ‘’ ğ‘ğ‘ğ‘ ğ‘œğ‘  ğ‘‘ğ‘’ ğ‘›Ã£ğ‘œ ğ‘¢ğ‘ ğ‘’ğ‘Ÿ)/ ğ‘›Ãºğ‘šğ‘’ğ‘Ÿğ‘œ ğ‘‘ğ‘’ ğ‘Ÿğ‘’ğ‘ğ‘¢ğ‘–ğ‘ ğ‘–Ã§Ãµğ‘’ğ‘  ğ‘Ÿğ‘’ğ‘ğ‘™ğ‘–ğ‘§ğ‘ğ‘‘ğ‘ğ‘ 

O simulador do cenÃ¡rio II Ã© dado pela funÃ§Ã£o â€œsimulacaoCenario2()â€ que tem os seguintes
parÃ¢metros de entrada:

* numRequisicoes - NÃºmero de requisiÃ§Ãµes que serÃ£o realizadas no experimento. Deve ser um
nÃºmero inteiro maior que 0.
* caso - qual Ã© o caso/tipo das caches. Os possÃ­veis valores de entrada sÃ£o: "FIFO", "LRU",
"Random" ou "Estatica"
* numConteudos - nÃºmero de conteÃºdos que podem ser requisitados. Deve ser um nÃºmero
inteiro maior que 0.
* tamCache - tamanho das caches. Deve ser um nÃºmero inteiro maior que 0.
* probabilidades - probabilidade de cada conteÃºdo ser requisitado. Deve ser passado uma lista
de tamanho igual ao nÃºmero de conteÃºdos. Por exemplo, se sÃ£o trÃªs conteÃºdos e possuem probabilidade
de requisiÃ§Ã£o uniforme, a lista passada deverÃ¡ ser [1/3,1/3,1/3]
* p - probabilidade de um canal falhar. Deve ser um float entre 0 e 1 e tem como default o valor
0.9.
* depurar - Booleano para indicar se deseja imprimir a depuraÃ§Ã£o do cÃ³digo ou nÃ£o. O default
Ã© o valor "False", onde nÃ£o se depura.
* cache1_inicial - Estado inicial de uma cache. Se nada for passado, ela irÃ¡ ser inicializada
aleatoriamente.
* cache2_inicial - Estado inicial da outra cache. Se nada for passado, ela irÃ¡ ser inicializada
aleatoriamente.
* cachesDiferentes - Booleano para indicar se deseja que as caches comecem em estados
diferentes ou iguais. O default Ã© o valor "True", onde comeÃ§am com em estados diferentes.


[â¬† Voltar ao topo](#caching-em-redes-com-perdas-e-atrasos)

# CenÃ¡rio III

O cenÃ¡rio III (com perdas e com atrasos) tambÃ©m Ã© composto por duas caches, cada uma com tamanho igual Ã  dois,
contudo apresenta atrasos nos canais de comunicaÃ§Ã£o e tambÃ©m hÃ¡ a probabilidade de um canal falhar.
Dessa forma, a cada requisiÃ§Ã£o feita pelo cliente, primeiramente Ã© avaliado se o canal funcionou e sÃ³
assim Ã© avaliado se a cache possui ou nÃ£o o conteÃºdo requisitado e tem o tempo para a requisiÃ§Ã£o chegar
nas caches e nos servidores. Nosso propÃ³sito nesse cenÃ¡rio Ã© identificar qual o tempo mÃ©dio para uma
requisiÃ§Ã£o ser atendida nas seguintes combinaÃ§Ãµes:
- 2 caches FIFO; 
- 2 caches LRU; 
- 2 caches Random; 
- 2 caches EstÃ¡ticas

## Simulador CenÃ¡rio III

Para simularmos o cenÃ¡rio III, criamos um simulador de eventos de tempo contÃ­nuo muito
mais complexo que os cenÃ¡rios anteriores, onde temos vÃ¡rios eventos para simular todo o processo que
uma requisiÃ§Ã£o passa atÃ© ser atendida, seja por uma das duas caches ou pelo servidor alternativo. Abaixo,
temos uma melhor descriÃ§Ã£o do funcionamento do simulador e da funÃ§Ã£o que o implementa.

O cenÃ¡rio III apresenta um funcionamento mais prÃ³ximo da realidade. Nossa modelagem do
problema funciona como descrito abaixo:

Temos que inicialmente, as caches sÃ£o inicializadas com os estados passados, caso nÃ£o sejam
passados, elas sÃ£o inicializadas de forma aleatÃ³ria com os conteÃºdos possÃ­veis, que nesse caso serÃ£o
representados por nÃºmeros inteiros de 1 ao numConteudos dado.

ApÃ³s isso, agenda-se um evento de uma requisiÃ§Ã£o para cada conteÃºdo na lista de eventos, esse
evento indica qual o tempo em que a requisiÃ§Ã£o irÃ¡ acontecer e qual conteÃºdo estarÃ¡ sendo requisitado.
O tempo do agendamento Ã© gerado de forma aleatÃ³ria seguindo a distribuiÃ§Ã£o exponencial tendo como
parÃ¢metro a taxa do conteÃºdo e a cada vez que um evento Ã© adicionado, a lista Ã© ordenada em funÃ§Ã£o
dos tempos apresentados em cada evento.

Com as caches inicializadas e uma requisiÃ§Ã£o agendada para cada conteÃºdo, inicia-se o
processo. Em termos de cÃ³digo, inicia-se um loop em cima da lista de eventos, onde para cada
requisiÃ§Ã£o, novos eventos sÃ£o gerados para simular seu atendimento. Primeiramente, tenta-se
encaminhar a requisiÃ§Ã£o com menor tempo presente na lista inicial de eventos para as duas caches. Aqui
temos um novo evento e mais dois possÃ­veis novos eventos para acrescentar na lista, pois tenta-se encaminhar a requisiÃ§Ã£o para cada cache, para isso gera-se um nÃºmero entre 0 e 1, se o nÃºmero for
menor ou igual ao parÃ¢metro p (que por default Ã© 0.9, o que implica que o canal tem 90% de chance de
funcionar), o canal funciona e cria-se um novo evento da requisiÃ§Ã£o chegando na cache, repete-se isso
para as duas. Assim, hÃ¡ a possibilidade da criaÃ§Ã£o de um evento onde a requisiÃ§Ã£o chega na cache 1
e/ou outro evento onde a requisiÃ§Ã£o chega na cache 2. AlÃ©m disso, Ã© gerado um nÃºmero aleatÃ³rio
seguindo a distribuiÃ§Ã£o exponencial com parÃ¢metro 1/ğ›¼ a para indicar o timer da requisiÃ§Ã£o, assim, criase um novo evento que serÃ¡ o timeout da requisiÃ§Ã£o.

Quando o evento da requisiÃ§Ã£o chegando na cache acontecer, Ã© verificado se a cache possui o
conteÃºdo requisitado. Se sim, cria-se um novo evento da requisiÃ§Ã£o sendo atendida pela cache agendado
para acontecer em n segundos, onde n Ã© calculado gerando um nÃºmero aleatÃ³rio seguindo a distribuiÃ§Ã£o
exponencial com parÃ¢metro 1/ğœ‡. JÃ¡ se a cache nÃ£o possuir, primeiro cria-se um novo evento onde cache
receberÃ¡ o conteÃºdo requisitado do servidor para assim poder atender a requisiÃ§Ã£o, o evento Ã© agendado
para acontecer em m segundos, onde m Ã© calculado gerando um nÃºmero aleatÃ³rio seguindo a
distribuiÃ§Ã£o exponencial com parÃ¢metro 1/ğœƒ (ğœƒ = âˆ no caso desse cenÃ¡rio) e sÃ³ quando esse novo evento
criado acontecer, que cria-se o evento da requisiÃ§Ã£o sendo atendida.

JÃ¡ se o evento timeout da requisiÃ§Ã£o chegar a acontecer, da forma que modelamos, ele cancela
todos os outros eventos referentes a requisiÃ§Ã£o que sofreu o timeout, isso para simular o cancelamento
do processo de tentativa de atender a requisiÃ§Ã£o pela caches, e cria um evento da requisiÃ§Ã£o sendo
atendida pelo servidor alternativo, o evento Ã© agendado para acontecer em l segundos, onde l Ã© calculado
gerando um nÃºmero aleatÃ³rio seguindo a distribuiÃ§Ã£o exponencial com parÃ¢metro 1/ğ›¾, onde nesse cenÃ¡rio.

Por Ãºltimo, quando o evento requisiÃ§Ã£o atendida acontece, seja pela cache 1, cache 2 ou pelo
servidor alternativo por conta do timeout, verifica-se se hÃ¡ mais requisiÃ§Ãµes abertas para o mesmo
conteÃºdo da que estÃ¡ sendo atendida, e cancela todos os processos referentes a essas requisiÃ§Ãµes junto
com os processos referentes Ã  que estÃ¡ sendo atendida, com exceÃ§Ã£o dos eventos intitulados â€œSistemaâ€,
o que representa quando uma requisiÃ§Ã£o serÃ¡ feita por um usuÃ¡rio e garante a taxa de chegada de cada
tipo de conteÃºdo. ApÃ³s isso, anota-se qual foi o tempo de atendimento de cada requisiÃ§Ã£o fazendo
tempo do evento requisiÃ§Ã£o atendida - tempo de chegada da requisiÃ§Ã£o.

Todos esses eventos acontecem para cada requisiÃ§Ã£o e se misturam, ou seja, pode ter um evento
da requisiÃ§Ã£o "req2" chegando na cache 1 enquanto e logo em seguida outra requisiÃ§Ã£o "req1" sendo
atendida pelo servidor alternativo.

ApÃ³s termos o nÃºmero especificado pelo parÃ¢metro de requisiÃ§Ãµes atendidas, seja pelo jeito que
for, as iteraÃ§Ãµes param e calcula-se o tempo de atendimento mÃ©dio das requisiÃ§Ãµes fazendo-se a soma
do tempo de atendimento de cada requisiÃ§Ã£o/nÃºmero de requisiÃ§Ãµes.

Lembrando que sempre que uma nova requisiÃ§Ã£o chega, outra requisiÃ§Ã£o para o mesmo
conteÃºdo Ã© agendada onde o tempo do agendamento Ã© gerado de forma aleatÃ³ria seguindo a distribuiÃ§Ã£o
exponencial com parÃ¢metro igual a probabilidade do conteÃºdo, dessa forma garantimos que cada
conteÃºdo seja requisitado seguindo sua taxa de chegada. A depuraÃ§Ã£o apresentada mais abaixo deve
ajudar a entender o funcionamento da simulaÃ§Ã£o aqui descrito que imaginamos que possa ser confusa
jÃ¡ que muitos eventos sÃ£o gerados. ApÃ³s o nÃºmero de requisiÃ§Ãµes pedidas serem feitas, verifica-se o
nÃºmero de casos em que nÃ£o ocorreu user miss, ou seja, os eventos onde a requisiÃ§Ã£o foi atendida e
finalmente calcula-se a probabilidade de user miss fazendo o seguinte cÃ¡lculo: 

(ğ‘›Ãºğ‘šğ‘’ğ‘Ÿğ‘œ ğ‘‘ğ‘’ ğ‘Ÿğ‘’ğ‘ğ‘¢ğ‘–ğ‘ ğ‘–Ã§Ãµğ‘’ğ‘  ğ‘Ÿğ‘’ğ‘ğ‘™ğ‘–ğ‘§ğ‘ğ‘‘ğ‘ğ‘  âˆ’ ğ‘›Ãºğ‘šğ‘’ğ‘Ÿğ‘œ ğ‘‘ğ‘’ ğ‘ğ‘ğ‘ ğ‘œğ‘  ğ‘‘ğ‘’ ğ‘›Ã£ğ‘œ ğ‘¢ğ‘ ğ‘’ğ‘Ÿ)/ğ‘›Ãºğ‘šğ‘’ğ‘Ÿğ‘œ ğ‘‘ğ‘’ ğ‘Ÿğ‘’ğ‘ğ‘¢ğ‘–ğ‘ ğ‘–Ã§Ãµğ‘’ğ‘  ğ‘Ÿğ‘’ğ‘ğ‘™ğ‘–ğ‘§ğ‘ğ‘‘ğ‘ğ‘ 

O simulador do cenÃ¡rio III Ã© dado pela funÃ§Ã£o abaixo que tem os seguintes parÃ¢metros de
entrada:
* numRequisicoes - NÃºmero de requisÃµes que serÃ£o realizadas no experimento. Deve ser um
nÃºmero inteiro maior que 0.
* caso - qual Ã© o caso/tipo das caches. Os possÃ­veis valores de entrada sÃ£o: "FIFO", "LRU",
"Random" ou "Estatica"
* numConteudos - nÃºmero de conteÃºdos que podem ser requisitados. Deve ser um nÃºmero
inteiro maior que 0.
* tamCache - tamanho das caches. Deve ser um nÃºmero inteiro maior que 0.


[â¬† Voltar ao topo](#caching-em-redes-com-perdas-e-atrasos)

# AplicaÃ§Ã£o dos Simuladores e ConclusÃ£o

Por serem muito extensos, os resultados das simulaÃ§Ãµes aplicadas e nossa conclusÃ£o se encontram no documento [RelatÃ³rio Trabalho Final - AD.pdf](https://github.com/siliconemonster/AD-TrabalhoFinal/blob/main/Relat%C3%B3rio%20Trabalho%20Final%20-%20AD.pdf)

# Colaboradores

<table>
  <tr>
    <td align="center">
      <a href="#">
        <img src="https://avatars.githubusercontent.com/u/20328857?v=4" width="100px;" alt="Foto de Aline Freie no GitHub"/><br>
        <sub>
          <a href="https://github.com/siliconemonster"><b>Aline Freire</b></a>
        </sub>
      </a>
    </td>
    <td align="center">
      <a href="#">
        <img src="https://avatars.githubusercontent.com/u/34246743?v=4" width="100px;" alt="Foto de LetÃ­cia Tavares no GitHub"/><br>
        <sub>
          <a href="https://github.com/leticiatavaresds"><b>LetÃ­cia Tavares</b></a>
        </sub>
      </a>
    </td>
</table>


[â¬† Voltar ao topo](#caching-em-redes-com-perdas-e-atrasos)

# LicenÃ§a

The MIT License (MIT) 2022 - Aline Freire e LetÃ­cia Tavares. Leia o arquivo [LICENSE.md](https://github.com/siliconemonster/AD-TrabalhoFinal/blob/master/LICENSE.md) para mais detalhes.


[â¬† Voltar ao topo](#caching-em-redes-com-perdas-e-atrasos)
